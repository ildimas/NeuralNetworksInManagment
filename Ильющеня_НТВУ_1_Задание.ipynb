{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ildimas/NeuralNetworksInManagment/blob/main/%D0%98%D0%BB%D1%8C%D1%8E%D1%89%D0%B5%D0%BD%D1%8F_%D0%9D%D0%A2%D0%92%D0%A3_1_%D0%97%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCRimqR0GUBq"
      },
      "source": [
        "# Homework 1: Нейронные сети в классификации изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wcXR4Zp8Htb2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZgk1BGNGUBr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9c1phNiGUBr"
      },
      "source": [
        "## 1. Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpN0O3qVGUBs"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "full_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "train_size = 50000\n",
        "val_size = 10000\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_sizes = [32, 64, 128]\n",
        "train_loaders = {}\n",
        "val_loaders = {}\n",
        "test_loaders = {}\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    train_loaders[batch_size] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loaders[batch_size] = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loaders[batch_size] = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoZWspmMGUBs"
      },
      "source": [
        "## 2. Имплементация моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMquojjDGUBs"
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(784, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.layers(x)\n",
        "\n",
        "class MediumMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.layers(x)\n",
        "\n",
        "class DeepMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(784, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_w_Rgq2GUBt"
      },
      "outputs": [],
      "source": [
        "class BasicCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7*7*32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmMtlECxGUBt"
      },
      "outputs": [],
      "source": [
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7*7*64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoqEJuzrGUBt"
      },
      "source": [
        "## 3. Тренировочная функция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTWvKjRiGUBu"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_acc = 100. * correct / total\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SYTTfmiGUBu"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(train_losses, val_losses, train_accs, val_accs, title):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(train_losses, label='Train Loss')\n",
        "    ax1.plot(val_losses, label='Val Loss')\n",
        "    ax1.set_title(f'{title} - Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(train_accs, label='Train Accuracy')\n",
        "    ax2.plot(val_accs, label='Val Accuracy')\n",
        "    ax2.set_title(f'{title} - Accuracy')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o2jkqBSGUBu"
      },
      "source": [
        "## 4. Обучение и оценка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA-fXsssGUBv"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "models = {\n",
        "    'Simple MLP': SimpleMLP(),\n",
        "    'Medium MLP': MediumMLP(),\n",
        "    'Deep MLP': DeepMLP(),\n",
        "    'Basic CNN': BasicCNN(),\n",
        "    'Complex CNN': ComplexCNN()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    print(f'\\nTraining {name}...')\n",
        "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "        model, train_loaders[64], val_loaders[64], criterion, optimizer, num_epochs=20, device=device\n",
        "    )\n",
        "\n",
        "    plot_metrics(train_losses, val_losses, train_accs, val_accs, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkhwX96LGUBv"
      },
      "source": [
        "## 5. CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77ry8qsfGUBv"
      },
      "outputs": [],
      "source": [
        "class CIFAR10CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(8*8*64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItBjwm5ZGUBv"
      },
      "outputs": [],
      "source": [
        "cifar_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=cifar_transform)\n",
        "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=cifar_transform)\n",
        "\n",
        "cifar_train_loader = DataLoader(cifar_train, batch_size=64, shuffle=True)\n",
        "cifar_test_loader = DataLoader(cifar_test, batch_size=64)\n",
        "\n",
        "cifar_model = CIFAR10CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_model.parameters(), lr=0.001)\n",
        "\n",
        "print('Training CIFAR-10 model...')\n",
        "train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "    cifar_model, cifar_train_loader, cifar_test_loader, criterion, optimizer, num_epochs=10, device=device\n",
        ")\n",
        "\n",
        "plot_metrics(train_losses, val_losses, train_accs, val_accs, 'CIFAR-10 CNN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Почему важна нормализация данных и как она влияет на процесс обучения?\n",
        "Нормализация приводит все входные признаки к сопоставимому масштабу (например, [0,1] или со средним 0 и дисперсией 1). Это помогает:\n",
        "- Ускорить сходимость градиентного спуска\n",
        "- Избежать доминирования признаков с большими значениями\n",
        "- Повысить устойчивость модели\n",
        "\n",
        "#### Как изменение batch_size влияет на скорость обучения и сходимость?\n",
        "- `batch_size=32`: стабильное обновление градиента, медленное обучение, лучшее обобщение\n",
        "- `batch_size=64`: баланс между шумом и скоростью\n",
        "- `batch_size=128`: быстрее обучение, но выше риск переобучения или плохого минимума\n",
        "\n",
        "> Эксперименты показывают, что `batch_size=64` часто является оптимумом между скоростью и качеством.\n",
        "\n",
        "#### Почему важно разделять данные на тренировочную, валидационную и тестовую выборки?\n",
        "- **Тренировочная**: обучение модели\n",
        "- **Валидационная**: подбор гиперпараметров и наблюдение переобучения\n",
        "- **Тестовая**: финальная оценка на \"невиданных\" данных\n",
        "Без валидации невозможно контролировать переобучение и сравнивать модели объективно.\n"
      ],
      "metadata": {
        "id": "UdUymyMKHuum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как количество параметров влияет на способность к обучению?\n",
        "- Меньше параметров: модель может недообучиться (underfitting)\n",
        "- Больше параметров: выше гибкость, но и выше риск переобучения\n",
        "Нужно находить баланс через валидацию.\n",
        "\n",
        "#### Сравнение функций активации:\n",
        "- `ReLU`: быстрая сходимость, популярна, но страдает от \"затухающего градиента\" для отрицательных значений\n",
        "- `Sigmoid`: плохо масштабируется, страдает от vanishing gradient\n",
        "- `Tanh`: центрирована, но тоже страдает от затухающего градиента\n",
        "- `LeakyReLU`: решает проблему ReLU с нулевыми градиентами\n",
        "\n",
        "> На практике ReLU/LeakyReLU дают лучшие результаты по скорости и качеству.\n",
        "\n",
        "#### Что происходит с градиентами при увеличении глубины сети?\n",
        "- Возникает **затухание** или **взрыв градиентов**\n",
        "- Это замедляет или делает невозможным обучение\n",
        "- Решения: нормализация (BatchNorm), инициализация, архитектуры с остаточными связями (ResNet)\n"
      ],
      "metadata": {
        "id": "fJyI12ZyHysO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Роль Padding и MaxPooling:\n",
        "- **Padding**: сохраняет размер выходной карты признаков, предотвращает потерю информации по краям\n",
        "- **MaxPooling**: уменьшает размерность, делает модель устойчивее к смещениям\n",
        "\n",
        "> Уменьшение размерности снижает количество параметров и ускоряет обучение\n",
        "\n",
        "#### Заменить MaxPooling на AveragePooling — что изменится?\n",
        "- Поведение станет более \"плавным\"\n",
        "- Потеряется акцент на ярко выраженных признаках\n",
        "- Accuracy может снизиться\n",
        "> Рекомендуется провести эксперимент и сравнить на валидации.\n",
        "\n",
        "#### Почему CNN эффективнее MLP для изображений?\n",
        "- CNN использует **локальные связи** и **shared weights**\n",
        "- Позволяет эффективно извлекать **локальные признаки**\n",
        "- MLP не учитывает структуру изображения, требует больше параметров\n"
      ],
      "metadata": {
        "id": "wRBPPaYeH3Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как влияет последовательное применение 2 Conv-слоев без Pooling?\n",
        "- Увеличивается **рецептивное поле**\n",
        "- Модель видит более глобальные шаблоны, но без снижения размерности\n",
        "\n",
        "#### Сравнение производительности базовой и усложненной CNN:\n",
        "- Усложнённая CNN (больше слоёв/фильтров): выше качество на сложных задачах\n",
        "- Но: дольше обучение и выше риск переобучения\n",
        "> Баланс достигается через регуляризацию и валидацию\n",
        "\n",
        "#### Влияние размера kernel_size (эксперимент):\n",
        "- `3x3`: захватывает мелкие детали\n",
        "- `5x5`: компромисс между локальным и глобальным\n",
        "- `7x7`: крупные шаблоны, но больше параметров и риск переобучения\n",
        "\n",
        "> Эксперименты показывают, что два слоя с `3x3` ядрами часто работают лучше, чем один `5x5` или `7x7`.\n"
      ],
      "metadata": {
        "id": "6dzdONucH4vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как определить переобучение?\n",
        "- Точность на валидации начинает ухудшаться, а на тренировке — расти\n",
        "- Увеличение loss на валидации при уменьшении loss на обучении\n",
        "\n",
        "#### Сравнение оптимизаторов:\n",
        "- **SGD**: прост, но медленно сходится\n",
        "- **RMSprop**: ускоряет за счёт адаптивных шагов\n",
        "- **Adam**: сочетает преимущества Momentum и RMSprop, хорошее качество и скорость\n",
        "\n",
        "> Adam чаще всего работает лучше \"из коробки\"\n",
        "\n",
        "#### Влияние learning rate (эксперимент):\n",
        "- `0.0001`: медленное обучение, стабильное\n",
        "- `0.001`: обычно оптимальное\n",
        "- `0.01`: быстрое, но может не сойтись (перескакивает минимум)\n",
        "\n",
        "#### Сравнение early stopping и L2-регуляризации:\n",
        "- **Early stopping**: прерывает обучение, если метрика валидации не улучшается\n",
        "- **L2-регуляризация**: штрафует большие веса\n",
        "\n",
        "> Совместное использование даёт наилучший эффект\n"
      ],
      "metadata": {
        "id": "RtTdaMaARslG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Какие архитектурные изменения требуются для CIFAR-10?\n",
        "- Увеличение глубины сети (из-за большего разнообразия классов)\n",
        "- BatchNorm, Dropout, Residual connections — для устойчивости\n",
        "\n",
        "#### Сравнение FashionMNIST и CIFAR-10:\n",
        "- FashionMNIST: grayscale, простые формы\n",
        "- CIFAR-10: цветные изображения, более сложные паттерны\n",
        "> Модели на CIFAR-10 требуют больше параметров и слоёв\n",
        "\n",
        "#### Transfer learning:\n",
        "- Использование предварительно обученных моделей (например, ResNet на ImageNet)\n",
        "- Замена классификатора на новую задачу\n",
        "> Ускоряет обучение и повышает точность\n",
        "\n",
        "#### Аугментации для CIFAR-10:\n",
        "- **Horizontal flip**, **Random crop**, **Color jitter**, **Rotation**\n",
        "> Улучшают обобщающую способность, имитируют разнообразие входов\n"
      ],
      "metadata": {
        "id": "DWuV5jfxRxTp"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}